import os
from torchvision import datasets , transforms, models


### TODO: Write data loaders for training, validation, and test sets
## Specify appropriate transforms, and batch_sizes

# Load data
data_dir = '/data/dog_images'

train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'
# Done: Define your transforms for the training, validation, and testing sets

data_transforms = { 'train'  : transforms.Compose([transforms.Resize(256),
                                                   transforms.RandomRotation(30),
                                                   transforms.CenterCrop(224),
                                                   #transforms.RandomResizedCrop(224),
                                                   transforms.RandomHorizontalFlip(),
                                                   transforms.ToTensor(),
                                                   transforms.Normalize([0.485,0.456,0.406],
                                                                        [0.229,0.224,0.225])]) ,
                    'valid' : transforms.Compose([transforms.Resize(256),
                                                  transforms.CenterCrop(224),
                                                  transforms.ToTensor(),
                                                  transforms.Normalize([0.485,0.456,0.406],
                                                                       [0.229,0.224,0.225])]) ,
                    'test' : transforms.Compose([transforms.Resize(256),
                                                 transforms.CenterCrop(224),
                                                 transforms.ToTensor(),
                                                 transforms.Normalize([0.485,0.456,0.406],
                                                                      [0.229,0.224,0.225])]) }

# Done: Load the datasets with ImageFolder

datasets = {x : datasets.ImageFolder(data_dir +'/' + x  , transform=data_transforms[x] ) for x in ['train', 'valid', 'test'] }

# Done: Using the image datasets and the trainforms, define the dataloaders
loaders_scratch = {x : torch.utils.data.DataLoader(datasets[x] , batch_size = 32 , shuffle= True ) for x in ['train' , 'valid','test']  }

import torch.nn as nn
import torch.nn.functional as F

# define the CNN architecture
class Net(nn.Module):
    ### TODO: choose an architecture, and complete the class
    def __init__(self):
        super(Net, self).__init__()
        ## Define layers of a CNN
        self.conv1 = nn.Conv2d(3,16,3,stride=1, padding=1)
        self.conv2 = nn.Conv2d(16,32,3,stride=1, padding=1)
        self.conv3 = nn.Conv2d(32,64,3, stride=1, padding=1)
        #self.conv4 = nn.Conv2d(64,128,3, stride=1, padding=1)
        self.maxpool = nn.MaxPool2d(2,2)
        self.fc1 = nn.Linear(64 * 28 * 28, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, 133)
        # dropout layer (p=0.2)
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        ## Define forward behavior
        x = F.relu(self.conv1(x))
        x = self.maxpool(x)
        x = F.relu(self.conv2(x))
        x = self.maxpool(x)
        x = F.relu(self.conv3(x))
        x = self.maxpool(x)
        #x = F.relu(self.conv4(x))
        #x = self.maxpool(x)
        x = x.view(-1, 64*28*28)
        #print('Conv4' , x.shape)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.relu(self.fc3(x))
        return x

#-#-# You so NOT have to modify the code below this line. #-#-#

# instantiate the CNN
model_scratch = Net()
print(model_scratch)

# move tensors to GPU if CUDA is available
if use_cuda:
    model_scratch.cuda()
    
    import torch.optim as optim

### TODO: select loss function
criterion_scratch = nn.CrossEntropyLoss()

### TODO: select optimizer
optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.0001)

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):
    """returns trained model"""
    # initialize tracker for minimum validation loss
    valid_loss_min = np.Inf 
    
    for epoch in range(1, n_epochs+1):
        # initialize variables to monitor training and validation loss
        train_loss = 0.0
        valid_loss = 0.0
        ###################
        # train the model #
        ###################
        model.train()
        for batch_idx, (data, target) in enumerate(loaders['train']):
            # move to GPU
            if use_cuda:
                data, target = data.cuda(), target.cuda()
            ## find the loss and update the model parameters accordingly
            ## record the average training loss, using something like
            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))
            optimizer.zero_grad()

            output = model.forward(data)

            loss = criterion(output, target)

            train_loss +=  ((1 / (batch_idx + 1)) * (loss.data - train_loss))

            loss.backward()

            optimizer.step()

        ######################    
        # validate the model #
        ######################
        model.eval()
        for batch_idx, (data, target) in enumerate(loaders['valid']):
            # move to GPU
            if use_cuda:
                data, target = data.cuda(), target.cuda()
            ## update the average validation loss
            output = model.forward(data)

            loss = criterion(output , target)

            valid_loss +=  ((1 / (batch_idx + 1)) * (loss.data - valid_loss))

            
        # print training/validation statistics 
        print('Epoch: {} \tTraining Loss: {:.6f}  \tValidation Loss: {:.6f} '.format(
            epoch, 
            train_loss,
            valid_loss
            ))
        
        ## TODO: save the model if validation loss has decreased
        if valid_loss < valid_loss_min :
            valid_loss_min = valid_loss
            torch.save(model.state_dict(), save_path)
    # return trained model
    return model


# train the model
model_scratch = train(100, loaders_scratch, model_scratch, optimizer_scratch, 
                      criterion_scratch, use_cuda, 'model_scratch.pt')

# load the model that got the best validation accuracy
model_scratch.load_state_dict(torch.load('model_scratch.pt'))
